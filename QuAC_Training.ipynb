{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuAC_Training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPr5WGQwb1AVwmdJ+92koIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Conv-AI/bert_hae/blob/master/QuAC_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy3g_8OgWszQ",
        "outputId": "575c469e-07b6-4b97-c9cc-5446d3d41e4b"
      },
      "source": [
        "!git clone https://github.com/Conv-AI/bert_hae.git\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_hae'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 62 (delta 0), reused 0 (delta 0), pack-reused 59\u001b[K\n",
            "Unpacking objects: 100% (62/62), done.\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gO9TlbcW1aN",
        "outputId": "4ec6cac5-ff39-4559-d43c-603cadc68800"
      },
      "source": [
        "%cd bert_hae\n",
        "!wget https://s3.amazonaws.com/my89public/quac/train_v0.2.json\n",
        "!wget https://s3.amazonaws.com/my89public/quac/val_v0.2.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert_hae\n",
            "--2020-12-04 17:36:54--  https://s3.amazonaws.com/my89public/quac/train_v0.2.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.170.229\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.170.229|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68114819 (65M) [application/json]\n",
            "Saving to: ‘train_v0.2.json’\n",
            "\n",
            "train_v0.2.json     100%[===================>]  64.96M  63.5MB/s    in 1.0s    \n",
            "\n",
            "2020-12-04 17:36:55 (63.5 MB/s) - ‘train_v0.2.json’ saved [68114819/68114819]\n",
            "\n",
            "--2020-12-04 17:36:55--  https://s3.amazonaws.com/my89public/quac/val_v0.2.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.140.78\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.140.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8929167 (8.5M) [application/json]\n",
            "Saving to: ‘val_v0.2.json’\n",
            "\n",
            "val_v0.2.json       100%[===================>]   8.51M  30.1MB/s    in 0.3s    \n",
            "\n",
            "2020-12-04 17:36:56 (30.1 MB/s) - ‘val_v0.2.json’ saved [8929167/8929167]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D13a4ePOrNLh",
        "outputId": "55609e7f-0dfe-4219-bfe6-4dd95aecdbbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r /content/drive/MyDrive/uncased_L-12_H-768_A-12 /content/bert_hae"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "TuD4nIgH1MsU",
        "outputId": "cd785457-e845-48ea-c34d-4a62f0b0ae36"
      },
      "source": [
        "import os\n",
        "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a25d2aa86ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtpu_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCahujRzg1Df",
        "outputId": "b92e77e4-d2f1-4acb-ad48-930fe93bacdf"
      },
      "source": [
        "%mkdir output\n",
        "%mkdir cache\n",
        "%cd cache\n",
        "%mkdir quac\n",
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bert_hae/cache\n",
            "/content/bert_hae\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zthLA6-_4YLG",
        "outputId": "83a5f1d6-4d33-4b8a-f25d-b3a1ab28e755"
      },
      "source": [
        "!python hae.py \\\n",
        "    --history=6 \\\n",
        "    --num_train_epochs=3.0 \\\n",
        "    --train_steps=24000 \\\n",
        "    --max_considered_history_turns=11 \\\n",
        "    --learning_rate=3e-05 \\\n",
        "    --warmup_proportion=0.1 \\\n",
        "    --evaluation_steps=8000 \\\n",
        "    --evaluate_after=32000 \\\n",
        "    --load_small_portion=True \\\n",
        "    --train_batch_size=12 \\\n",
        "    --max_answer_length=40 \\\n",
        "    --use_tpu=True \\\n",
        "    --tpu_name=tpu_address \\\n",
        "    --num_tpu_cores=8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert_hae/optimization.py:89: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "logtostderr : False\n",
            "alsologtostderr : False\n",
            "log_dir : \n",
            "v : -1\n",
            "verbosity : -1\n",
            "logger_levels : {}\n",
            "stderrthreshold : fatal\n",
            "showprefixforinfo : True\n",
            "run_with_pdb : False\n",
            "pdb_post_mortem : False\n",
            "pdb : False\n",
            "run_with_profiling : False\n",
            "profile_file : None\n",
            "use_cprofile_for_profiling : True\n",
            "only_check_args : False\n",
            "op_conversion_fallback_to_while_loop : False\n",
            "test_random_seed : 301\n",
            "test_srcdir : \n",
            "test_tmpdir : /tmp/absl_testing\n",
            "test_randomize_ordering_seed : \n",
            "xml_output_file : \n",
            "f : \n",
            "bert_config_file : ./uncased_L-12_H-768_A-12/bert_config.json\n",
            "vocab_file : ./uncased_L-12_H-768_A-12/vocab.txt\n",
            "output_dir : ./output\n",
            "quac_train_file : ./train_v0.2.json\n",
            "quac_predict_file : ./val_v0.2.json\n",
            "init_checkpoint : ./uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "do_lower_case : True\n",
            "max_seq_length : 384\n",
            "doc_stride : 128\n",
            "max_query_length : 64\n",
            "do_train : True\n",
            "do_predict : True\n",
            "train_batch_size : 6\n",
            "predict_batch_size : 6\n",
            "learning_rate : 3e-05\n",
            "num_train_epochs : 2.0\n",
            "warmup_proportion : 0.1\n",
            "save_checkpoints_steps : 1000\n",
            "evaluation_steps : 5\n",
            "evaluate_after : 0\n",
            "iterations_per_loop : 1000\n",
            "n_best_size : 4\n",
            "max_answer_length : 30\n",
            "use_tpu : False\n",
            "tpu_name : None\n",
            "tpu_zone : None\n",
            "gcp_project : None\n",
            "master : None\n",
            "num_tpu_cores : 8\n",
            "verbose_logging : False\n",
            "history : 6\n",
            "load_small_portion : True\n",
            "dataset : quac\n",
            "cache_dir : ./cache/\n",
            "max_considered_history_turns : 11\n",
            "train_steps : 20\n",
            "WARNING:tensorflow:From hae.py:54: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:55: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:55: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:64: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/cqa_supports.py:95: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/cqa_supports.py:107: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:<<<<<<<<<< load_small_portion is on! >>>>>>>>>>\n",
            "attempting to load train features from cache\n",
            "WARNING:tensorflow:<<<<<<<<<< load_small_portion is on! >>>>>>>>>>\n",
            "attempting to load val features from cache\n",
            "val feature cache does not exist, generating\n",
            "val features generated\n",
            "WARNING:tensorflow:From hae.py:168: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/modeling.py:189: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/modeling.py:432: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/modeling.py:380: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/bert_hae/modeling.py:720: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/bert_hae/modeling.py:298: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:192: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:198: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:218: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert_hae/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "***** Running training *****\n",
            "  Num orig examples = %d 78\n",
            "  Num train_features = %d 477\n",
            "  Batch size = %d 12\n",
            "  Num steps = %d 24000\n",
            "WARNING:tensorflow:From hae.py:230: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:234: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:236: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:237: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From hae.py:238: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-12-04 09:37:21.596405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-04 09:37:21.661230: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-04 09:37:21.661305: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f151db57e69e): /proc/driver/nvidia/version does not exist\n",
            "2020-12-04 09:37:21.696731: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-12-04 09:37:21.697061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ccf2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-04 09:37:21.697114: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From hae.py:242: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "training step: 0, total_loss: 5.221743583679199\n",
            "training step: 1, total_loss: 4.300408363342285\n",
            "training step: 2, total_loss: 4.513776779174805\n",
            "training step: 3, total_loss: 4.869707107543945\n",
            "training step: 4, total_loss: 5.493894577026367\n",
            "training step: 5, total_loss: 5.273882865905762\n",
            "training step: 6, total_loss: 5.571169853210449\n",
            "training step: 7, total_loss: 5.691438674926758\n",
            "training step: 8, total_loss: 5.9738616943359375\n",
            "training step: 9, total_loss: 4.885970115661621\n",
            "training step: 10, total_loss: 5.929633140563965\n",
            "epoch finished!\n",
            "training step: 11, total_loss: 5.215441703796387\n",
            "training step: 12, total_loss: 4.304443836212158\n",
            "training step: 13, total_loss: 4.484040260314941\n",
            "training step: 14, total_loss: 4.761922836303711\n",
            "training step: 15, total_loss: 5.458123207092285\n",
            "training step: 16, total_loss: 5.240655899047852\n",
            "training step: 17, total_loss: 5.558304786682129\n",
            "training step: 18, total_loss: 5.647670269012451\n",
            "training step: 19, total_loss: 5.960628509521484\n",
            "training step: 20, total_loss: 4.8463850021362305\n",
            "training step: 21, total_loss: 5.997193336486816\n",
            "epoch finished!\n",
            "training step: 22, total_loss: 5.175331115722656\n",
            "training step: 23, total_loss: 4.250486850738525\n",
            "training step: 24, total_loss: 4.424015998840332\n",
            "training step: 25, total_loss: 4.793190002441406\n",
            "training step: 26, total_loss: 5.384787559509277\n",
            "training step: 27, total_loss: 5.151571750640869\n",
            "training step: 28, total_loss: 5.527409553527832\n",
            "training step: 29, total_loss: 5.573390007019043\n",
            "training step: 30, total_loss: 5.886203765869141\n",
            "training step: 31, total_loss: 4.765379905700684\n",
            "training step: 32, total_loss: 5.83854341506958\n",
            "epoch finished!\n",
            "WARNING:tensorflow:From /content/bert_hae/cqa_supports.py:497: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Writing predictions to: ./output/predictions_32.json\n",
            "INFO:tensorflow:Writing nbest to: ./output/nbest_predictions_32.json\n",
            "WARNING:tensorflow:From hae.py:333: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "evaluation: 32, total_loss: 3.9301304817199707, f1: 0.11811340301393156, followup: 0.0, yesno: 0.27233115468409586, heq: 0.013616557734204794, dheq: 0.0\n",
            "\n",
            "Model saved in path ./output/model_32.ckpt\n",
            "epoch finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laYvRCAF5Rwm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}